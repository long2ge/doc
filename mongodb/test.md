MongoDB采用B-树索引


Mongodb 更新失败解决方案

现象：

WriteResult res = mongoTemplate.updateFirst(query, updateObj, "ServerToAgentReq_SMS");

获取res.getN()返回值时，发现偶尔情况下该返回值为0，表示该更新操作没有更新到任何数据。并且如果是多线程并发更新，失败几率大大提高。

官网表示不能保证更新操作的成功性....

方案：

一次失败后，另起线程多次重试。


### 面向服务的架构
1. 用户模块，订单模块，权限模块，流程模块
2. 把这些模块对外抽取，然后以服务的形式对外公开。
3. 我们把系统的功能模块打散，把各个模块功能组拼到一块可以形成一个系统。
4. 代码可以重用性更高；维护性更高；分流，可以提升系统的性能。

### 游标
1. 通俗的说，游标不是查询结果，而是查询的返回资料或者接口。
2. 通过这个接口，你可以逐条读取。就像php中的fopen打开文件，得到一个资源一样，通过资源，可以一行一行处理。

### 索引类型
1. 组合索引
2. 单键索引
3. 多值索引
4. 地址位置索引
5. 全文索引
6. TTL索引
7. 部分索引 ： 只取部分的数据建立索引
8. 哈希索引

### 组合索引
1. 组合索引的最佳方式ESR原则
精确 Equal : 匹配的字段放最前面
排序 Sort : 条件放中间
范围  Range ： 匹配的字段放最后s
同样适合ES，ER

### 其他索引技巧
1. 对BI / 报表专用节点单独创建索引
2. 该从节点priority设置为0
3. 关闭该从节点
4. 以单机模式启动
5. 添加索引（分析用）
6. 关闭该从节点，以副文集模式启动


### mongo数据库定位
1. 原则上Oracle和Mysql能做的事情，Mongodb都能做（包括ACID事务）
2. 优点：横向扩展能力，数据量或并发量增加时候架构可以自动扩展
3. 优点：灵活模型，适合迭代开发，数据模型多变场景
4. 优点：Json数据结构，适合微服务/REST API


### mongo功能的优势
1.  亿级以上的数据量
2. 灵活表结构
3. 高并发读
4. 高并发写
5. 跨地区集群
6. 分片集群
7. 地理位置查询
8. 聚合计算
9. 异构数据
10. 大宽表


### 基于场景选择Mongodb
1. 移动/小程序App
    场景特点：
        基于REST API / JSON
        快速迭代，数据结构变化频繁
        地理位置功能
        爆发增长可能性
        高可用
    MongoDB选型考量：
        文档模型可以支持不同的结构
        原生地理位置功能
        横向扩展能力支撑爆发增长
        复制集机制快速提供高可用
        摩拜单车/Keep/ADP
2. 电商
    场景特点：
        商品信息包罗万象
        商品的属性不同品类差异很大
        数据库模式设计困难
    MongoDB选型考量：
        文档模型可以集成不同商品属性
        可变模型适合迭代
        京东商品/小红书/GAP
3. 内容管理
    场景特点：
        内容数据多样，文本，图片，视频
        扩展困难，数据量爆发增长
    MongoDB选型考量：
        Json结构可以支持非结构化数据
        分片架构可以解决扩展问题
        Adobe AEM / Sitecore
4. 物联网
    场景特点：
        传感器的数据结构往往是半结构化
        传感器数量很大，采集频繁
        数据量很容易增长到数亿到百亿
    MongoDB选型考量：
        Json结构可以支持半结构化数据，使用分片能力支持海量数据
        Json数据更加容易和其他系统通过REST API 进行集成
        华为 / Bosch / Mindsphere
5. Saas应用
6. 主机分流
    场景特点：
        金融行业传统采用IBM或者小机
        传统瀑布开发模式流程长成本高
        结构不易改变，难于适应新需求
        根据某银行的统计，99%的数据库操作为读流量
        基于MIPS付费，读流量成本高
    MongoDB选型考量：
        使用实时同步机制，将数据同步出来到MongoDB
        使用MongoDB的高性能查询能力来支撑业务的读操作
        相比于关系模型数据库，更加容易迁入数据并构建成JSON模型进行API服务
7. 实时分析
    场景特点：
        流数据计算
        快速计算，秒级返回
    MongoDB选型考量：
        使用MongoDB缓存机制，可以利用内存计算加速
        使用MongoDB聚合框架，实现分析功能
        使用微分片脚骨的并发计算来大量缩减计算时间
8. 关系型迁移
    场景特点：
        基于Oracle / MySQL / SQLServer 的历史应用
        数据量增长或者使用者变多以后性能变慢
        分库分表需要应用配合
        结构死板，增加新需求复杂困难
    MongoDB选型考量：
        高性能高并发的数据库性能
        无需应用分库分表，集群自动解决扩容问题
        动态模型适合快速开发
        头条 / 网易 / 百度 / 东航 / 中国银行


### 一次数据库请求过程中发生了什么？
1. 选择节点
2. 获取连接(新建连接 -> 连接上限 -> (Y : 排队等待 -> (占用连接 or 超时)， N：认证 -> 建立连接))
3. 占用连接
4. 发起请求
5. 获得结果
6. 释放连接
7. 正常结束

### 选择节点
1. 对于复制集读操作，选择那个节点由 readPreference决定
    primary / secondary / nearest
2. 如果不希望一个远距离节点被选择，应做到以下之一
    将它设置为隐藏节点，通过标签控制可以选择的节点，使用nearest方式


### 排队等待
1. 加大连接数（不一定有用）
2. 优化查询性能

### 连接和认证
1. 设置minPoolSize一次性创建足够的连接
2. 避免突发的大量请求

### 数据库执行
1. 包含片
2. 所有片执行还是特定片执行
3. 评估执行计划
4. 获取ticket，占用ticket或者排队等待获取ticket（如果超时，一场退出）
5. 执行请求
6. 释放ticket
7. 如果是特定片直接返回结果，不是就合并结果


### ticket 排队等待
优化语句，减少ticket的占用时间
zlib压缩方式也可能引起ticket不足，从而造成长时间的ticket占用

### 读的执行请求
1. 执行请求
2. 加载资源，将本次请求所需的数据，索引加载到缓存
3. 搜索，用已加载的数据找到所需的结果（索引扫描或者集合扫描）
4. 排序，如果执行顺序，按照指定顺序返回（索引排序，内存排序）

### 写的执行请求
1. 执行请求
2. 定位数据(索引扫描，集合扫描)，如果j ： true，，写journal，直接返回应用
3. j ： false, 写缓存（写oplog， 写索引，写数据，事务执行）
4. 返回应用

### 写操作
1. 磁盘速度必须比写入速度要快才能保持速度。
### 数据库合并结果
1. 顺序不重要就不要排序
2. 尽可能使用带片键的查询条件以缉拿少参与查询的分片数


应用 -> mongos(config) -> 片

###  性能瓶颈
1. 选择访问入口节点 -> 排队等待ticket -> 应用 / 驱动 -> mongos
2. 等待数据库连接 -> 执行请求 -> mongos 片
3. 创建连接和完成认证 -> 合并执行结果


###  什么是writeConcern
1. 决定一个写操作落到多少个节点上才算成功
2. wrietConcern的取值包括：
    0，发起写操作，不关心是否成功。
    1～集群最大数据节点数：写操作需要被复制到指定节点数才算成功。
    majority ： 写操作需要被复制到大多数节点上才算成功。
3. 发起写操作的程序将阻塞到写操作到达指定的节点数为止。
4. 3节点复制集不做任何特别设定，写入primary后直接返回。
5. w:majority 大多数节点确认模式
6. w:all, 全部节点确认模式

### journal
1. mongodb的journal，简单来说就是用于数据故障恢复和持久化数据的，它以日志方式来记录。
2. 定义如何才算成功。
3. true ： 写操作落入journal文件中才算成功
4. false ： 写操作到达内存算作成功。

###  管道（Pipeline）和步骤（Stage）
1. 这个那个聚合运算过程成为管道，它是由多个步骤组成的，每个管道：接收一系列文档（原始数据），每个步骤对这些文档进行一系列运算。结果文档输出给下一个步骤。
2. 常见步骤包括，$match 过滤, $project 投影, $sort 排序, $group 分组, $skip / $limit  结果限制, $lookup 左外连接



###  读操作
1. 从哪里读，关注数据节点，位置。由readPreference来解决。
2. 什么洋的数据可以读，关注数据的隔离，由readConcern来解决。
3. readPreference 决定使用哪一个节点来满足正在发起的读请求
    primary ： 只选择主姐弟那；
    primaryPreferred ： 优先选择主节点，如果不可用则选择从节点
    secondary ： 只选择从节点
    secondaryPreferred ： 优先选择从节点，如果从节点不可用则选择主节点
    nearest ： 选择最近的节点
4. readPreference 场景举例
5. 用户下订单后马上将用户转到订单详情页 primary / primaryPreferred 因为从节点可能还没有复制到新的订单
6. 用户查询自己下过的订单 secondary / secondaryPreferred 查询历史订单对时效性通常没有太高要求。
7. 生成报表  secondary。报表的时效性要求不高，但资源需求不大，可以在从节点单独处理，避免对线上用户造成影响。
8. 将用户上传的图片分发到全世界。让各地用户能够就近读取 - nearest。 每个地区的应用选择最近的姐弟那读取数据。


### readPreference 和 Tag
1. readPreference只能控制使用一类节点。
2. Tag则可以将节点选择控制到一个或几个节点。
3. 可以使用Tag来达到这样的控制目的，{purpose：“online”}，在线应用读取时指定online。

### 注意的事项
1. 指定readPreference时应该注意高可用问题。例如指定Primary，primary宕机，则没有可读节点，
如果业务允许，应该选择primaryPreferred。
2. Tag也回出现同样的问题。如果需要，可以选择多个节点有相同的Tag。
3. 还需要考虑优先级，选举权综合考虑。


### readConcern
1. 在readPreference选择了指定的节点后，readConcern决定这个节点上的数据那些是可读的，类似关系数据库的隔离级别。
    available：读取所有可用的数据
    local：读取所有可用并且属于当前分片的数据
    majority:读取在大多数节点上提交完成的数据
    linearizable：可线性化读取文档
    snapshot：读取最近快照中的数据

2. available和local的区别在于， chunk X 从A转移到B的过程中，A和B都有部分X的数据，local读取的数据不包括X，available在分片上有什么就读什么。
3. 选择local会对结果集进行过滤会造成额外的消耗。在一些无关紧要的场景喜爱，可以考虑available。
4. 从主节点默认选择local。从从节点读取数据时默认是available。向前面兼容的原因。
5. majority，只读取大多数据节点上都提交了的数据。
6. majority的实现方式，维护多个快照来链接不同的版本。每个被大多数节点确认过的版本都将是一个快照。快照持续到没有人使用为止才被删除。
7. 使用local参数，可以直接查询到写入数据。使用majority，只能查询到被多数节点确认过的数据。update于remove于上同理。
8. mongo中的回滚，写操作到达大多数节点之前都是不安全的，一旦主节点崩溃，
而从节还没有恢复到该次操作，刚刚的写操作就丢失了。
从事务的角度看，可以认为是事务被回滚了。。
9. 如果在一次写操作到达大多数节点前读取写操作，然后因为系统故障
该操作回滚了，则发生脏读。使用majority可以有效避免脏读。
10. 设置成snapshot，保证在事务中读：不出现脏读，不出现不可重复读，不出现幻读。
因为所有的读都将使用同一个快照，直到事务提交为止快照才能释放。
### 如何实现安全的读写分离？
1. 向主节点写入一条数据，马上从从节点读取这条数据。
2. 使用writeConcern + readConcern majority来解决。
3. readCocnern ： majority对应事务中隔离级别中的那个？
Read Uncommited
Read Connitted     对应这个
Repeatable Read
Seriazable


### 事务
1. 4.2开始支持了多文档事务，但是这不代表可以毫无节制使用。
2. 对事务的使用原则应该是：能不用就不用。
3. 通过合理低设计文档模型，可以规避大部分使用事务的必要性。
4. 事务修改一个文档，事务外尝试修改一个文档，则事务外的修改
会等待事务完成才能继续进行。
5. 事务完成之前，事务外的操作对该事务所做的修改不可以访问。
6. 如果事务内使用snapshot 则可以达到Repeatable Read

### 注意事项
1， 事务默认60秒，超时取消。
2. 涉及事务的分片不能使用仲裁节点。
3. 事务会影响chunk迁移效率。正在迁移的chunk也可能造成事务提交失败，重试即可。
4. 多文档事务中的读操作必须使用主节点读。
5. readConcern 只应该在事务级别设置，不能每次读写操作上。


