MongoDB采用B-树索引


Mongodb 更新失败解决方案

现象：

WriteResult res = mongoTemplate.updateFirst(query, updateObj, "ServerToAgentReq_SMS");

获取res.getN()返回值时，发现偶尔情况下该返回值为0，表示该更新操作没有更新到任何数据。并且如果是多线程并发更新，失败几率大大提高。

官网表示不能保证更新操作的成功性....

方案：

一次失败后，另起线程多次重试。


### 面向服务的架构
1. 用户模块，订单模块，权限模块，流程模块
2. 把这些模块对外抽取，然后以服务的形式对外公开。
3. 我们把系统的功能模块打散，把各个模块功能组拼到一块可以形成一个系统。
4. 代码可以重用性更高；维护性更高；分流，可以提升系统的性能。

### 游标
1. 通俗的说，游标不是查询结果，而是查询的返回资料或者接口。
2. 通过这个接口，你可以逐条读取。就像php中的fopen打开文件，得到一个资源一样，通过资源，可以一行一行处理。

### 索引类型
1. 组合索引
2. 单键索引
3. 多值索引
4. 地址位置索引
5. 全文索引
6. TTL索引
7. 部分索引 ： 只取部分的数据建立索引
8. 哈希索引

### 组合索引
1. 组合索引的最佳方式ESR原则
精确 Equal : 匹配的字段放最前面
排序 Sort : 条件放中间
范围  Range ： 匹配的字段放最后s
同样适合ES，ER

### 其他索引技巧
1. 对BI / 报表专用节点单独创建索引
2. 该从节点priority设置为0
3. 关闭该从节点
4. 以单机模式启动
5. 添加索引（分析用）
6. 关闭该从节点，以副文集模式启动


### mongo数据库定位
1. 原则上Oracle和Mysql能做的事情，Mongodb都能做（包括ACID事务）
2. 优点：横向扩展能力，数据量或并发量增加时候架构可以自动扩展
3. 优点：灵活模型，适合迭代开发，数据模型多变场景
4. 优点：Json数据结构，适合微服务/REST API


### mongo功能的优势
1.  亿级以上的数据量
2. 灵活表结构
3. 高并发读
4. 高并发写
5. 跨地区集群
6. 分片集群
7. 地理位置查询
8. 聚合计算
9. 异构数据
10. 大宽表


### 基于场景选择Mongodb
1. 移动/小程序App
    场景特点：
        基于REST API / JSON
        快速迭代，数据结构变化频繁
        地理位置功能
        爆发增长可能性
        高可用
    MongoDB选型考量：
        文档模型可以支持不同的结构
        原生地理位置功能
        横向扩展能力支撑爆发增长
        复制集机制快速提供高可用
        摩拜单车/Keep/ADP
2. 电商
    场景特点：
        商品信息包罗万象
        商品的属性不同品类差异很大
        数据库模式设计困难
    MongoDB选型考量：
        文档模型可以集成不同商品属性
        可变模型适合迭代
        京东商品/小红书/GAP
3. 内容管理
    场景特点：
        内容数据多样，文本，图片，视频
        扩展困难，数据量爆发增长
    MongoDB选型考量：
        Json结构可以支持非结构化数据
        分片架构可以解决扩展问题
        Adobe AEM / Sitecore
4. 物联网
    场景特点：
        传感器的数据结构往往是半结构化
        传感器数量很大，采集频繁
        数据量很容易增长到数亿到百亿
    MongoDB选型考量：
        Json结构可以支持半结构化数据，使用分片能力支持海量数据
        Json数据更加容易和其他系统通过REST API 进行集成
        华为 / Bosch / Mindsphere
5. Saas应用
6. 主机分流
    场景特点：
        金融行业传统采用IBM或者小机
        传统瀑布开发模式流程长成本高
        结构不易改变，难于适应新需求
        根据某银行的统计，99%的数据库操作为读流量
        基于MIPS付费，读流量成本高
    MongoDB选型考量：
        使用实时同步机制，将数据同步出来到MongoDB
        使用MongoDB的高性能查询能力来支撑业务的读操作
        相比于关系模型数据库，更加容易迁入数据并构建成JSON模型进行API服务
7. 实时分析
    场景特点：
        流数据计算
        快速计算，秒级返回
    MongoDB选型考量：
        使用MongoDB缓存机制，可以利用内存计算加速
        使用MongoDB聚合框架，实现分析功能
        使用微分片脚骨的并发计算来大量缩减计算时间
8. 关系型迁移
    场景特点：
        基于Oracle / MySQL / SQLServer 的历史应用
        数据量增长或者使用者变多以后性能变慢
        分库分表需要应用配合
        结构死板，增加新需求复杂困难
    MongoDB选型考量：
        高性能高并发的数据库性能
        无需应用分库分表，集群自动解决扩容问题
        动态模型适合快速开发
        头条 / 网易 / 百度 / 东航 / 中国银行


### 一次数据库请求过程中发生了什么？
1. 选择节点
2. 获取连接(新建连接 -> 连接上限 -> (Y : 排队等待 -> (占用连接 or 超时)， N：认证 -> 建立连接))
3. 占用连接
4. 发起请求
5. 获得结果
6. 释放连接
7. 正常结束

### 选择节点
1. 对于复制集读操作，选择那个节点由 readPreference决定
    primary / secondary / nearest
2. 如果不希望一个远距离节点被选择，应做到以下之一
    将它设置为隐藏节点，通过标签控制可以选择的节点，使用nearest方式


### 排队等待
1. 加大连接数（不一定有用）
2. 优化查询性能

### 连接和认证
1. 设置minPoolSize一次性创建足够的连接
2. 避免突发的大量请求

### 数据库执行
1. 包含片
2. 所有片执行还是特定片执行
3. 评估执行计划
4. 获取ticket，占用ticket或者排队等待获取ticket（如果超时，一场退出）
5. 执行请求
6. 释放ticket
7. 如果是特定片直接返回结果，不是就合并结果


### ticket 排队等待
优化语句，减少ticket的占用时间
zlib压缩方式也可能引起ticket不足，从而造成长时间的ticket占用

### 读的执行请求
1. 执行请求
2. 加载资源，将本次请求所需的数据，索引加载到缓存
3. 搜索，用已加载的数据找到所需的结果（索引扫描或者集合扫描）
4. 排序，如果执行顺序，按照指定顺序返回（索引排序，内存排序）

### 写的执行请求
1. 执行请求
2. 定位数据(索引扫描，集合扫描)，如果j ： true，，写journal，直接返回应用
3. j ： false, 写缓存（写oplog， 写索引，写数据，事务执行）
4. 返回应用

### 写操作
1. 磁盘速度必须比写入速度要快才能保持速度。
### 数据库合并结果
1. 顺序不重要就不要排序
2. 尽可能使用带片键的查询条件以缉拿少参与查询的分片数


应用 -> mongos(config) -> 片

###  性能瓶颈
1. 选择访问入口节点 -> 排队等待ticket -> 应用 / 驱动 -> mongos
2. 等待数据库连接 -> 执行请求 -> mongos 片
3. 创建连接和完成认证 -> 合并执行结果


###  什么是writeConcern
1. 决定一个写操作落到多少个节点上才算成功
2. wrietConcern的取值包括：
    0，发起写操作，不关心是否成功。
    1～集群最大数据节点数：写操作需要被复制到指定节点数才算成功。
    majority ： 写操作需要被复制到大多数节点上才算成功。
3. 发起写操作的程序将阻塞到写操作到达指定的节点数为止。
4. 3节点复制集不做任何特别设定，写入primary后直接返回。
5. w:majority 大多数节点确认模式
6. w:all, 全部节点确认模式

### journal
1. mongodb的journal，简单来说就是用于数据故障恢复和持久化数据的，它以日志方式来记录。
2. 定义如何才算成功。
3. true ： 写操作落入journal文件中才算成功
4. false ： 写操作到达内存算作成功。

###  管道（Pipeline）和步骤（Stage）
1. 这个那个聚合运算过程成为管道，它是由多个步骤组成的，每个管道：接收一系列文档（原始数据），每个步骤对这些文档进行一系列运算。结果文档输出给下一个步骤。
2. 常见步骤包括，$match 过滤, $project 投影, $sort 排序, $group 分组, $skip / $limit  结果限制, $lookup 左外连接



###  读操作
1. 从哪里读，关注数据节点，位置。由readPreference来解决。
2. 什么样的数据可以读，关注数据的隔离，由readConcern来解决。
3. readPreference 决定使用哪一个节点来满足正在发起的读请求
    primary ： 只选择主姐弟那；
    primaryPreferred ： 优先选择主节点，如果不可用则选择从节点
    secondary ： 只选择从节点
    secondaryPreferred ： 优先选择从节点，如果从节点不可用则选择主节点
    nearest ： 选择最近的节点
4. readPreference 场景举例
5. 用户下订单后马上将用户转到订单详情页 primary / primaryPreferred 因为从节点可能还没有复制到新的订单
6. 用户查询自己下过的订单 secondary / secondaryPreferred 查询历史订单对时效性通常没有太高要求。
7. 生成报表  secondary。报表的时效性要求不高，但资源需求不大，可以在从节点单独处理，避免对线上用户造成影响。
8. 将用户上传的图片分发到全世界。让各地用户能够就近读取 - nearest。 每个地区的应用选择最近的姐弟那读取数据。


### readPreference 和 Tag
1. readPreference只能控制使用一类节点。
2. Tag则可以将节点选择控制到一个或几个节点。
3. 可以使用Tag来达到这样的控制目的，{purpose：“online”}，在线应用读取时指定online。

### 注意的事项
1. 指定readPreference时应该注意高可用问题。例如指定Primary，primary宕机，则没有可读节点，
如果业务允许，应该选择primaryPreferred。
2. Tag也回出现同样的问题。如果需要，可以选择多个节点有相同的Tag。
3. 还需要考虑优先级，选举权综合考虑。


### readConcern
1. 在readPreference选择了指定的节点后，readConcern决定这个节点上的数据那些是可读的，类似关系数据库的隔离级别。
    available：读取所有可用的数据
    local：读取所有可用并且属于当前分片的数据
    majority:读取在大多数节点上提交完成的数据
    linearizable：可线性化读取文档
    snapshot：读取最近快照中的数据

2. available和local的区别在于， chunk X 从A转移到B的过程中，A和B都有部分X的数据，local读取的数据不包括X，available在分片上有什么就读什么。
3. 选择local会对结果集进行过滤会造成额外的消耗。在一些无关紧要的场景喜爱，可以考虑available。
4. 从主节点默认选择local。从从节点读取数据时默认是available。向前面兼容的原因。
5. majority，只读取大多数据节点上都提交了的数据。
6. majority的实现方式，维护多个快照来链接不同的版本。每个被大多数节点确认过的版本都将是一个快照。快照持续到没有人使用为止才被删除。
7. 使用local参数，可以直接查询到写入数据。使用majority，只能查询到被多数节点确认过的数据。update于remove于上同理。
8. mongo中的回滚，写操作到达大多数节点之前都是不安全的，一旦主节点崩溃，
而从节还没有恢复到该次操作，刚刚的写操作就丢失了。
从事务的角度看，可以认为是事务被回滚了。。
9. 如果在一次写操作到达大多数节点前读取写操作，然后因为系统故障
该操作回滚了，则发生脏读。使用majority可以有效避免脏读。
10. 设置成snapshot，保证在事务中读：不出现脏读，不出现不可重复读，不出现幻读。
因为所有的读都将使用同一个快照，直到事务提交为止快照才能释放。
### 如何实现安全的读写分离？
1. 向主节点写入一条数据，马上从从节点读取这条数据。
2. 使用writeConcern + readConcern majority来解决。
3. readCocnern ： majority对应事务中隔离级别中的那个？
Read Uncommited
Read Connitted     对应这个
Repeatable Read
Seriazable


### 事务
1. 4.2开始支持了多文档事务，但是这不代表可以毫无节制使用。
2. 对事务的使用原则应该是：能不用就不用。
3. 通过合理低设计文档模型，可以规避大部分使用事务的必要性。
4. 事务修改一个文档，事务外尝试修改一个文档，则事务外的修改
会等待事务完成才能继续进行。
5. 事务完成之前，事务外的操作对该事务所做的修改不可以访问。
6. 如果事务内使用snapshot 则可以达到Repeatable Read

### 注意事项
1， 事务默认60秒，超时取消。
2. 涉及事务的分片不能使用仲裁节点。
3. 事务会影响chunk迁移效率。正在迁移的chunk也可能造成事务提交失败，重试即可。
4. 多文档事务中的读操作必须使用主节点读。
5. readConcern 只应该在事务级别设置，不能每次读写操作上。



### mongo的优势
1. 去掉关系型数据库的多表关联
2. 结构灵活，没有固定的字段
3. 快速开发，代码量更少
4. 原生的高可用（复制集提供99.9999高可用）和横向扩展能力（分片架构）


### 复制集的作用
1. mongo复制集的主要意义在于实现服务高可用
2. 现实依赖两个方法的功能：
2.1 数据写入时将数据迅速复制到另一个独立节点上
2.2 在接受写入的节点发生故障时自动选举出一个新的替代节点
3. 实现高可用的时候，复制集实现了其他几个附加作用：
    数据分发：将数据从一个区域复制到另外一个区域，减少另一个区域的读延迟。
    读写分离：不同类型的压力分别在不同的节点上执行。
    异地容灾：在数据中心故障时候快速切换到异地。

### 复制集结构
1. 一个经典的复制集由3个以上具有投票权的节点组成
2. 一个主节点（Primary）：接受写入操作和选举时投票
3. 两个或者多个从节点（secondary）：复制主节点上的新数据和选举时投票
4. 不推荐使用Arbiter（投票节点），偶数的机器有可能出现投票相同的情况，投票节点的作用就是让投票数变成奇数。

### 复制集配置
1. 是否具有投票权 v 参数 ： 有则参与投票
2. 优先级（priority 参数）：优先级越高的节点越优先成为主节点。优先级为0的节点无法成为主节点。
3. 隐藏（hidden参数）：复制数据，但对应用不可见。隐藏节点可以具有投票权，但优先级必须为0。
4. 延迟（slaveDelay 参数）：复制n秒之前的数据，保持与主节点的时间差。


### 复制集注意的问题
1. 硬件：因为正常的复制集节点都有可能成为主节点，他们的地位是一样的，因此硬件设备必须一样。
2. 为了保证节点不会同时宕机，各节点使用的硬件必须具有独立性。
3. 软件：复制集各节点软件版本必须一致，以避免出现不可预知的问题。
4. 增加节点不会增加系统写性能。


### 数据是如何复制的 oplog
1. 当一个修改操作，无论是插入，更新或删除，到达主节点时，它对数据的操作将被记录下来（经过一些必要的转换），这些记录成为oplog
2. 从节点通过在主节点上打开一个tailable游标不断获取新进入主节点的oplog，并在自己的数据上回放，一次保证跟主节点的数据一致。


### 通过选举完成故障恢复
1. 具有投票权的节点之间两两互相发送心跳
2. 当5次心跳未收到时，判断为节点失联
3. 如果失联的是主节点，从节点会发起选举，选出新的主节点
4. 如果失联的是从节点，则不会产生新的选举
5. 选举基于RAFT一致性算法实现，选举成功的必要条件是大多数投票节点存活
6. 复制集中最多可以有50个节点，但具有投票权的节点最多7个。

选举过程很复杂,实际使用中总结为两点:
一般情况下需要5s左右进行选主.
如果新选举出的主节点立马挂掉,至少需要30s时间重新选主.




### mongodb 全家桶
1. mongod 数据库软件
2. mongo 命令行工具，管理数据库
3. mongos 路由进程，分片环境下使用
4. mongodump / mongorestore 备份和恢复工具
5. mongoexport / mongoimport CSV 和 JSON 导入和导出，主要用于不同系统之间数据迁移
6. Compass GUI管理工具
7. Ops Manager 企业版  集群管理工具
8. BI Connector  企业版  SQL 解释器 / BI 套接件
9. MongoDB Charts 企业版 可视化软件
10. Atlas 付费和免费    云托管服务，包括永久免费云数据库


###  分片集群的特点
1. 应用全透明，无需要特殊处理
2. 数据自动均衡
3. 动态扩容，无须下线
4. 提供三种分片方式

### 分片方式
1. 基于范围
    片键范围查询性能好
    优化读
    数据分布可能不均匀
    容易有热点
2. 基于Hash
    数据分布均匀，写优化
    范围查询效率低
    适合：日志，物联网等高并发场景
3. 基于zone / tag
    地区分片

### 小结
1. 分片集群可以有效解决性能瓶颈和系统扩容问题
2. 分片额外消耗较多，管理复杂，尽量不要分片    



### 如何做好分片的架构
1. 是否需要分片？
2. 需要多少分片？
3. 数据的分布规则
4. 选择需要分片的表
5. 选择正确的片键
6. 使用合适的均衡策略
7. 足够的资源 CPU， RAM， 存储


### 合理的分片
1. 数据量不超过3T，尽可能保持在2T一个片。
2. 关于索引：常用索引必须容纳进内存。
3. 需要多少个分片？
A = 所需存储总量 / 单服务器可挂载容器   8T / 2T = 4
B = 工作集大小 / 单服务器内存容量  400G / 256G * 0.6 = 3
C = 并发量总数 / 单服务器并发量 * 0.7  30000 / 9000 * 0.7 = 6

分片数量 = max(A,B,C) = 6


###  分片的概念
片键 shard key ： 文档中的一个字段
文档 doc ： 包含 shard key 的一行数据
块  chunk ： 包含N个文档
分片 shard ： 包含N个chunk
集群 cluster ： 包含N个分片

### 选择合适片键
1. 取值基数
2. 取值分布
3. 分散写，集中读
4. 被尽可能多的业务场景用到
5. 避免单调递增或递减的片键
6. 选择基数大的片键（ 值的范围就是基数 ）
    对于小基数的片键，因为备选值有限，那么块的总数量就有限。
    随着数据增多，块的太小就会越来越大。
    太大的块，会导致水平扩展时移动块会非常困难
结论： 取值基数要大。
7. 选择分布均匀的片键
    对于分布不均匀的片键，造成某些块的数据量急剧增大，这些块的压力随之增大，数据均衡以chunk为单位，所以系统无能为力。
结论 ： 取值分布应尽可能均匀。
8. 定向性好。对主要查询要具有定向能力
    用片键作为条件查询，mongos可以直接定位到具体的分片，不用的话，mongs需要把查询发送到4个分片，等最后一个分片响应才会返回数据。
9. 例如： 用户di就符合定向性和分布性，但是基数不够大，可以增加time做组合片键。


### 足够的资源
1. mongos与config通常消耗很少的资源，可以选择低的虚拟机。
2. 资源的重点在于shard服务器
    足够容纳热数据索引的内存
    正确创建索引后CPU通常不会成为瓶颈，除非设计非常多的计算
    磁盘尽量使用SSD
3. 实际测试是最好的检验，看你的资源配置是否完备。
4. 监控各个资源标准，达到60%就需要考虑扩展。
    因为需要新的资源，申请新资源需要时间
    扩展后数据需要均衡，均衡需要时间。应该保证新数据入库速度慢于均衡速度。
    均衡需要资源，如果资源即将耗尽，均衡也是低效的。


### change stream
1. 类似mysql的触发器，可以监控集合增删改和数据库的变化。
2. 基于oplog实现。在oplog上开启一个tailable cursor来
追踪所有复制集上的变更操作，最终调用应用中定义的回调函数。
3. invalidate: drop / rename / dropDatabase将
导致invalidate被触发，并关闭change stream
4. 只推送大多数节点上提交的变更操作。
5. 未开启majority readConcern的集群无法使用。
6. 只对某些类型的变更事件感兴趣，可以使用聚合管道的过滤步骤
过滤事件。
7. 集群的变更复制，在源集群中订阅change steam，一旦得到任何变更
立即写入目标集群。
8. 当一个微服务变更数据库时，其他微服务得到通知并做出相应的变更。


### 链接配置
1. maxPoolsize 连接池大小
2. max wait time 最大等待时间
3. write concern
4. read concern


### 注意
1. 不要在mongos或复制集上层放置负载均衡器，让驱动处理负载均衡和自动故障恢复。
2. 游标已经遍历完，则会自动关闭，如果没有遍历完，需要手动关闭。否则游标将
在服务器存在10分钟。优化方式是将条件收紧。
3. 防止使用太长的字段名
4. 防止使用太深的数组嵌套，超过2层操作比较复杂。
5. 不使用中文，标点符号等。
6. 处理分页问题，避免使用count，count需要遍历完所有符合的文档才返回结果。
7. 无论何时，事务的使用能不用就不用。
8. 模型设计优先事务，尽可能用模型设计规避事务。
9. 不要使用过大的事务。控制在1000个文档更新之内。
10. 真的要使用事务的时候，尽可能把事务操作的文档控制在一个分片之内。