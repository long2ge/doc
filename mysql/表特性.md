### 表压缩
1. Myisam引擎支持对表的压缩,压缩后的空间上比压缩前会减少60%-70%,但是压缩后的表是只读。
    可以使用--unpack参数解压缩表，但是解压缩后的表依然是只读的。
2. InnoDB引擎的压缩特色效果不错，压缩完后快和MyISAM引擎差不多了。
   不过压缩后事务并发性能下降非常严重，从这个角度来看，它适合用于对压缩比较高、但对并发事务要求不高的场景
    
### 表设计字段是否有空
1. 尽量避免NULL：应该指定列为NOT NULL，除非你想存储NULL。
2. 在MySQL中，含有空值的列很难进行查询优化。
3. 因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值。
4. null会影响索引的统计，一般会默认null为同一个值，这样这个索引的筛选价值就降低了，影响优化器的判断。
5. 当然也可以调整参数，使得null被认为是不同的值。
6. 可空列被索引后，每条记录都需要一个额外的字节，还能导致MYisam 中固定大小的索引变成可变大小的索引。
7. 可空列需要更多的存储空间;



1、空值是不占用空间的

2、mysql中的NULL其实是占用空间的，



# 主键
如果要插入的表没有主键或非空的唯一键的话， innodb就会从全局
为这行分配一个row_id。 由于是全局锁，非常的影响插入性能。
1. 显式的定义一个 INT 类型自增字段的主键，这个字段可以仅用于做主键，不做其他用途
2. 如果不显式定义主键的话，可能会导致InnoDB每次都需要对新数据行进行排序，严重损害性能
3. 尽量保证不对主键字段进行更新修改，防止主键字段发生变化，引发数据存储碎片，降低IO性能
4. 如果需要对主键字段进行更新，请将该字段转变成一个唯一索引约束字段，另外创建一个没有其他业务意义的自增字段做主键
5. 主键字段类型尽可能小，能用SMALLINT就不用INT，能用INT就不用BIGINT
6. 主键字段放在数据表的第一顺序

# 建立自增主键的原因是：
Innodb中的每张表都会有一个聚集索引，而聚集索引又是以物理磁盘顺序来存储的，自增主键会把数据自动向后插入，避免了插入过程中的聚集索引排序问题。聚集索引的排序，必然会带来大范围的数据的物理移动，这里面带来的磁盘IO性能损耗是非常大的。
而如果聚集索引上的值可以改动的话，那么也会触发物理磁盘上的移动，于是就可能出现page分裂，表碎片横生。



# 临时表的产生
1. sql执行会生成一个巨大的临时表，当内存放不下时，要全部copy 到磁盘，导致IO飙升，时间开销增大。
2. MySQL临时表分为“内存临时表”和“磁盘临时表”，
从5.7.5开始，新增一个系统选项 internal_tmp_disk_storage_engine 可定义磁盘临时表的引擎类型为 InnoDB，而在这以前，只能使用 MyISAM。而在5.6.3以后新增的系统选项 default_tmp_storage_engine 是控制 CREATE TEMPORARY TABLE 创建的临时表的引擎类型，在以前默认是MEMORY，不要把这二者混淆了。

3. 直接使用磁盘临时表的场景
   
   1)表包含TEXT或者BLOB列;
   
   2)GROUP BY 或者 DISTINCT 子句中包含长度大于512字节的列;
   
   3)使用UNION或者UNION ALL时，SELECT子句中包含大于512字节的列;
   
   
### MySQL会创建临时表的几种情况
    1、UNION查询；
    2、用到TEMPTABLE算法或者是UNION查询中的视图；
    3、ORDER BY和GROUP BY的子句不一样时；
    4、表连接中，ORDER BY的列不是驱动表中的；（指定了联接条件时，满足查询条件的记录行数少的表为[驱动表]，未指定联接条件时，行数少的表为[驱动表]，多表联合查询时）
    5、DISTINCT查询并且加上ORDER BY时；
    6、SQL中用到SQL_SMALL_RESULT选项时；
    7、FROM中的子查询；
    8、子查询或者semi-join时创建的表；
    
    
    
### 一张表存储多少数据性能是最高的
    对于表记录数需要考虑的是记录数的临界点，即：表达到这个记录数后，
    表大小（数据和索引）超过了Innodb buffer pool的大小；而设计时推荐尽量设计和试用行长度小而精的表。
    
1. 行长度对性能影响更大，行越长性能越低
2. 表记录数本身对性能影响不大，关键是表的大小是否小于Innodb buffer pool。







### “快照”在MVCC里是怎么工作的？

    在MySQL里，有两个“视图”的概念：
    
    一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view ... ，而它的查询方法与表一样。
    另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。
    
    
    
    
    
    InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。
    
    而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。
    
    同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。
    
    也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。

对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：

1. 已提交的事务或者是当前事务自己生成的，这个数据是可见的；（已经提交事务）

2. 将来启动的事务生成的，是肯定不可见的；(未开始事务)


如果落在黄色部分，那就包括两种情况(已经开始事务，但是还没有提交)
a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；
b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。


事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101], 事务C的视图数组是[99,100,101,102]。

### 唯一索引还是普通索引
#### 查询过程
假设，执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。

对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。
对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。
那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。


#### 更新过程 change buffer

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，
在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。
在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。
通过这种方式就能保证这个数据逻辑的正确性。


需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。

将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。

除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。

显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。
而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。



### 什么条件下可以使用change buffer呢？

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。

因此，唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。

change buffer用的是buffer pool里的内存，因此不能无限增大。change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。

现在，你已经理解了change buffer的机制，那么我们再一起来看看如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的。

第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB的处理流程如下：

对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；
对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。
这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。

但，这不是我们关注的重点。

第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB的处理流程如下：

对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。
将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

之前我就碰到过一件事儿，有个DBA的同学跟我反馈说，他负责的某个业务的库内存命中率突然从99%降低到了75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。

### change buffer的使用场景
通过上面的分析，你已经清楚了使用change buffer对更新过程的加速作用，也清楚了change buffer只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用change buffer都可以起到加速作用吗？

因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，
会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。






普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。




redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。





### 字符串索引
使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。

在区分度低的情况下的处理方法

第一种方式是使用倒序存储。
第二种方式是使用hash字段。


    直接创建完整索引，这样可能比较占用空间；
    
    创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
    
    倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
    
    创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。
    
    
### WAL技术

当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。


利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。


执行时机
第一种是“redo log写满了，要flush脏页”，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。

第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB用缓冲池（buffer pool）管理内存，

刷脏页操作





对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。